---
title: "Lesson 8"
author: "Team Rython, Dainius Masiliunas and Tim Weerman"
date: "January 13, 2016"
output: html_document
---

Apache License 2.0 

***

####Needed packages
```{r eval = TRUE echo = FALSE}
library(raster)
```

***

####Source
```{r eval = TRUE}
source("src/RMSE.r")
```
Calculate the Root Mean Squared Error
```{r eval = FALSE}
RMSE = function(truth, prediction)
{
    return(sqrt(mean((truth-prediction)^2, na.rm=TRUE)))
}

StratifiedRMSE = function(truth, prediction)
{
}
```

```{r eval = TRUE}
source("src/LinearModel.r")
```
Creates a linear model and prints its summary, and if desired whether some covariates ought to be removed from the model, and a plot of residuals
```{r eval = FALSE}
lmValidation = function(..., printstep=FALSE, printplot=FALSE)
{
    LM = lm(...)
    print(summary(LM))
    if (printstep)
        step(LM)
    if (printplot)
        plot(LM)
    return(LM)
}

predictValidation = function(object, ..., truthlayer = "", range = c(-Inf, +Inf), plothist = FALSE, plotcomparison = FALSE)
{
    Prediction = predict(object, ...)
    Prediction[Prediction < range[1]] = NA
    Prediction[Prediction > range[2]] = NA
    if (plothist)
        hist(Prediction, breaks = 200, main="Histogram of predicted values")
    if (plotcomparison)
    {
        TruthExists = try(class(object[[truthlayer]]))
        if (class(TruthExists) == "try-error")
        {
            warning("Requested a comparison plot, but could not find a layer to compare to!")
            return(Prediction)
        }
        op = par(mfrow=c(1,2))
        plot(Prediction, colNA="black", main="Predicted values")
        plot(object[[truthlayer]], colNA="black", main="Ground truth")
        par(op)
    }
    return(Prediction)
}
```

***

####Download/load information
```{r eval= TRUE}
GetFromWURgit = function(filename)
{
    download.file(paste("https://github.com/GeoScripting-WUR/AdvancedRasterAnalysis/raw/gh-pages/data/", filename, sep=""),
        paste("data/", filename, sep=""), "wget")
    return(paste("data/", filename, sep=""))
}
load(GetFromWURgit("GewataB1.rda"))
load(GetFromWURgit("GewataB2.rda"))
load(GetFromWURgit("GewataB3.rda"))
load(GetFromWURgit("GewataB4.rda"))
load(GetFromWURgit("GewataB5.rda"))
load(GetFromWURgit("GewataB7.rda"))
load(GetFromWURgit("vcfGewata.rda"))
load(GetFromWURgit("trainingPoly.rda"))
```

***

**Produce one or more plots that demonstrate the relationship between the Landsat bands and the VCF tree cover.** 
```{r eval= TRUE }
DataBrick = brick(GewataB1, GewataB2, GewataB3, GewataB4, GewataB5, GewataB7, vcfGewata)
names(DataBrick) = c("Blue", "Green", "Red", "NIR", "SWIR", "Emission", "VCF")
```

Sanitise data
```{r eval= TRUE }
DataBrick[["VCF"]][DataBrick[["VCF"]] > 100] = NA
pairs(DataBrick)
```

We can conclude that they are all negatively correlated with VCF, except for NIR. The bands are also highly correlated with each other.

***

**Create an lm() model and show a summary (e.g. using summary()) of the model object you created. Which predictors (bands) are probably most important in predicting tree cover?**
```{r eval= TRUE}
DataValues = as.data.frame(getValues(DataBrick))
LM = lm(VCF ~ Blue + Green + Red + NIR + SWIR + Emission, data=DataValues)
summary(LM) # Emission is insignificant
step(LM) # Emission can be dropped
LM = lm(VCF ~ Blue + Green + Red + NIR + SWIR, data=DataValues)
summary(LM) # Everything is significant
step(LM) # Nothing can be dropped, the most significant bands are NIR and green
```
NB: a linear model isn't very appropriate, because normality and independence assumptions are violated!  

**Plot the predicted tree cover raster and compare with the original VCF raster.**
```{r eval = TRUE}
BrickSubset = dropLayer(DataBrick, "Emission")
Prediction = predict(BrickSubset, model=LM, na.rm=TRUE)
Pred = Prediction
Pred[Pred < 0] = NA
hist(Prediction, breaks = 200)
op = par(mfrow=c(1,2))
plot(Pred, colNA="black")
plot(DataBrick[["VCF"]], colNA="black")
par(op)

hist(DataBrick[["VCF"]])
```

If we use only independent variables:
```{r eval = TRUE}
ReducedBrick = dropLayer(DataBrick, "Emission")
ReducedBrick = dropLayer(ReducedBrick, "Green")
ReducedBrick = dropLayer(ReducedBrick, "Red")
ReducedBrick = dropLayer(ReducedBrick, "SWIR")
pairs(ReducedBrick)
ReducedLM = lm(VCF ~ Blue + NIR, data=DataValues)
summary(ReducedLM)
drop1(ReducedLM)
plot(ReducedLM)
RedPrediction = predict(ReducedBrick, model=ReducedLM, na.rm=TRUE)
hist(RedPrediction, breaks = 200)
RedPrediction[RedPrediction < 0] = NA
op = par(mfrow=c(1,2))
plot(RedPrediction, colNA="black")
plot(ReducedBrick[["VCF"]], colNA="black")
par(op)
```

***

**Compute the RMSE between your predicted and the actual tree cover values.**
```{r eval = TRUE}
RMSE(getValues(ReducedBrick[["VCF"]]), getValues(RedPrediction))
```

***

**Are the differences between the predicted and actual tree cover the same for all of the 3 classes we used for the random forest classfication?**  
Unfortunately, zonal() just passes a vector of numbers, not a matrix. So we have to calclate RMSE manually from a difference raster.
```{r eval = TRUE}
trainingRaster = rasterize(trainingPoly, DataBrick[["VCF"]], field='Class')
differenceRaster = overlay(ReducedBrick[["VCF"]], RedPrediction, fun=function(truth, prediction){(truth-prediction)^2}, filename=paste(".grd"))
zonestats = zonal(differenceRaster, trainingRaster, fun="mean")
rownames(zonestats) = levels(trainingPoly@data$Class)
zonestats
```

***


